{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hindi POS Tagger using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In corpus linguistics, part-of-speech tagging (POS tagging or PoS tagging or POST), also called grammatical tagging is the process of marking up a word in a text (corpus) as corresponding to a particular part of speech, based on both its definition and its context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing NLTK library, corpus and tagger\n",
    "import nltk\n",
    "from nltk.corpus import indian\n",
    "from nltk.tag import tnt\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package indian to\n",
      "[nltk_data]     C:\\Users\\Pranshu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package indian is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Pranshu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading Indian Languages Corpora which consists Hindi, Bangla, Marathi and Telugu corpus respectively\n",
    "nltk.download(\"indian\")\n",
    "\n",
    "# Downloading Tokenizers \n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the POS Tagger Model using Hindi dataset\n",
    "def train():\n",
    "    taggedSet = \"hindi.pos\"\n",
    "    wordSet = indian.sents(taggedSet)\n",
    "    count = 0\n",
    "    \n",
    "    # Joining dataset words to form a sentence \n",
    "    for sen in wordSet:\n",
    "        count = count + 1\n",
    "        sen = \"\".join(\n",
    "            [\n",
    "                \" \" + i if not i.startswith(\"'\") and i not in string.punctuation else i\n",
    "                for i in sen\n",
    "            ]\n",
    "        ).strip()\n",
    "        # Viewing individual corpus sentence\n",
    "        # print(count, sen, \"sentences\")\n",
    "        \n",
    "    # Total Sentence Count\n",
    "    print(\"Total sentences in the tagged file are\", count)\n",
    "    \n",
    "    # Spliting dataset into Training Data and Test Data\n",
    "    trainPerc = 0.9\n",
    "\n",
    "    # Assigning the last index for Training Data and first index of Test Data\n",
    "    trainRows = int(trainPerc * count)\n",
    "    testRows = trainRows + 1\n",
    "\n",
    "    # Slicing the corpus\n",
    "    data = indian.tagged_sents(taggedSet)\n",
    "    train_data = data[:trainRows]\n",
    "    test_data = data[testRows:]\n",
    "\n",
    "    # Stats\n",
    "    print(\"Training dataset length: \", len(train_data))\n",
    "    print(\"Testing dataset length: \", len(test_data))\n",
    "    pos_tagger = tnt.TnT()\n",
    "    pos_tagger.train(train_data)\n",
    "    print(\"Accuracy: \", pos_tagger.evaluate(test_data))\n",
    "    \n",
    "    return pos_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tagging function to tag all words in a sentence\n",
    "def tagger(pos_tagger, sentenceToBeTagged):\n",
    "    tokenized = nltk.word_tokenize(sentenceToBeTagged)\n",
    "    return pos_tagger.tag(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences in the tagged file are 540\n",
      "Training dataset length:  486\n",
      "Testing dataset length:  53\n",
      "Accuracy:  0.8111964873765093\n",
      "[('प्रधानमंत्री', 'NN'), ('की', 'PREP'), ('सिफारिश', 'NN'), ('पर', 'PREP'), ('मंत्रियों', 'NN'), ('के', 'PREP'), ('एक', 'QFNUM'), ('पैनल', 'NN'), ('का', 'PREP'), ('गठन', 'NVB'), ('किया', 'VFM'), ('गया', 'VAUX'), ('था', 'VAUX'), ('।', 'PUNC')]\n"
     ]
    }
   ],
   "source": [
    "# Main Driving Module\n",
    "if __name__ == \"__main__\":\n",
    "    pos_tagger = train()\n",
    "    sentence_to_be_tagged = \"प्रधानमंत्री की सिफारिश पर मंत्रियों के एक पैनल का गठन किया गया था ।\"\n",
    "    print(tagger(pos_tagger, sentence_to_be_tagged))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
